{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vocational-assessment",
   "metadata": {},
   "source": [
    "# 手写数字识别\n",
    "\n",
    "\n",
    "### 问题：分类问题（10类）\n",
    "\n",
    "### 输入：灰度图像（28×28个像素）\n",
    "\n",
    "### 输出：分类0-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd78c8d8",
   "metadata": {},
   "source": [
    "# 0.超参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "513206fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "每次在训练集中提取64张图像进行批量化训练，目的是提高训练速度。\n",
    "就好比搬砖，一次搬一块砖头的效率肯定要比一次能搬64块要低得多\n",
    "\"\"\"\n",
    "BATCH_SIZE = 64\n",
    "#学习率，学习率一般为0.01，0.1等等较小的数，为了在梯度下降求解时避免错过最优解\n",
    "LR = 0.001\n",
    "\"\"\"\n",
    "EPOCH 假如现在我有1000张训练图像，因为每次训练是64张，\n",
    "每当我1000张图像训练完就是一个EPOCH，训练多少个EPOCH自己决定\n",
    "\"\"\"\n",
    "EPOCH = 1\n",
    "\"\"\"\n",
    "现在我要训练的训练集是系统自带的，需要先下载数据集，\n",
    "当DOWNLOAD_MNIST为True是表示学要下载数据集，一但下载完，保存\n",
    "然后这个参数就可以改为False，表示不用再次下载\n",
    "\"\"\"\n",
    "DOWNLOAD_MNIST = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-great",
   "metadata": {},
   "source": [
    "# 1.导入数据\n",
    "\n",
    "### 原始数据（来自keras.datasets.mnist）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "monetary-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手动导入数据\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() #mnist.load_data('路径')为下载并保存数据集位置，默认位置在C:\\Users\\管理员\\.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb8fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# pytorch导入\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "#训练集\n",
    "# 读取\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train = True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=DOWNLOAD_MNIST\n",
    ")\n",
    "\n",
    "# 划分\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2 )\n",
    "#每个batch_size的shape为[64, 1, 28, 28]\n",
    "print(\"样本\")\n",
    "print(train_data.train_data.shape)\n",
    "print(train_data.train_data[:3])\n",
    "print(\"标签\")\n",
    "print(train_data.train_labels.shape)\n",
    "print(train_data.train_labels[:3])\n",
    "\n",
    "\n",
    "\n",
    "# 测试集\n",
    "# 读取\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train = False,\n",
    ")\n",
    "\n",
    "# 处理\n",
    "\n",
    "test_x = Variable(torch.unsqueeze(test_data.test_data, dim=1), volatile=True).type(torch.FloatTensor)[:2000]/255.0\n",
    "\"\"\"\n",
    "test_data.test_data中的shape为[10000, 28, 28]代表1w张图像，都是28x28，当时并未表明channels,因此在unsqueeze在1方向想加一个维度，\n",
    "则shape变为[10000, 1, 28, 28]，然后转化为tensor的float32类型，取1w张中的2000张，并且将其图片进行归一化处理，避免图像几何变换的影响\n",
    "\"\"\"\n",
    "#标签取前2000\n",
    "test_y = test_data.test_labels[:2000]\n",
    "\n",
    "print(\"样本\")\n",
    "print(test_x.shape)\n",
    "print(test_x[:3])\n",
    "print(\"标签\")\n",
    "print(test_y.shape)\n",
    "print(test_y[:3])\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-craps",
   "metadata": {},
   "source": [
    "# 2.创建自己的Datasets数据集\n",
    "\n",
    "from torch.utils.data import Dataset, TensorDataset ,DataLoader\n",
    "\n",
    "\n",
    ">1.将数据转为tensor格式\n",
    ">>`数据 = torch.tensor(mumpy数据)` \n",
    "\n",
    "\n",
    ">2.数据处理\n",
    ">>图像数据处理：\n",
    ">>>**图像数据列表维度shape：[图像数量,通道维数,图像长像素,图像宽像素]**  \n",
    ">>>缺少通道维黑白图像处理:`图片样本data = Variable(torch.unsqueeze(图片样本data, dim=1), volatile=True).type(torch.FloatTensor)/255`  \n",
    ">>>数据类型转换:`数据变量 = 数据变量.type(torch.FloatTensor)`\n",
    "\n",
    ">>标签处理\n",
    ">>>转换为one-hot编码:`标签labels = utils.to_categorical(标签labels)`  \n",
    ">>>标签转换成long数据格式：`标签labels = 标签labels.long()`\n",
    "\n",
    ">3.创建数据集\n",
    ">>`数据集 = TensorDataset(样本data, 标签labels)`\n",
    "\n",
    ">4.加载数据集\n",
    ">>`train_loader = DataLoader(train_dataset, batch_size=120)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d962467",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 对分类标签y进行one-hot编码  utils.to_categorical(标签列表, num_classes=标签类别数, dtype='编码后标签格式')\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "print(\"编码前\")\n",
    "print(train_labels)\n",
    "\n",
    "train_labels = utils.to_categorical(train_labels)\n",
    "test_labels = utils.to_categorical(test_labels)\n",
    "\n",
    "print(\"编码后\")\n",
    "print(train_labels)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2900642b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n",
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-8705a23add60>:23: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  train_images = Variable(torch.unsqueeze(train_images, dim=1), volatile=True).type(torch.FloatTensor)/255\n",
      "<ipython-input-3-8705a23add60>:24: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  test_images = Variable(torch.unsqueeze(test_images, dim=1), volatile=True).type(torch.FloatTensor)/255\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "print(train_images)\n",
    "\n",
    "# 1.把数据转换成tensor格式\n",
    "train_images = torch.tensor(train_images)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "\n",
    "test_images = torch.tensor(test_images)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "print(train_images.shape)\n",
    "\n",
    "\n",
    "# 2. 数据处理\n",
    "# 将标签转换成long格式\n",
    "train_labels = train_labels.long()\n",
    "test_labels = test_labels.long()\n",
    "\n",
    "# 图像数据调整增加维度 [图片数, 长, 宽]->[图片数, 通道数, 长, 宽], 将数据转为tensor的Float格式\n",
    "train_images = Variable(torch.unsqueeze(train_images, dim=1), volatile=True).type(torch.FloatTensor)/255\n",
    "test_images = Variable(torch.unsqueeze(test_images, dim=1), volatile=True).type(torch.FloatTensor)/255\n",
    "\n",
    "print(train_images.shape)\n",
    "\n",
    "\n",
    "# 3.创建数据集\n",
    "train_dataset = TensorDataset(train_images, train_labels)\n",
    "test_dataset = TensorDataset(test_images, test_labels)\n",
    "\n",
    "\n",
    "# 4.加载数据集\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader =DataLoader(test_dataset, batch_size=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-duration",
   "metadata": {},
   "source": [
    "# 3.构建网络\n",
    "\n",
    "```python\n",
    "# 导入包\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义神经网络类\n",
    "class 自定义神经网络类名(nn.Module):\n",
    "    # 可学习参数的层（如全连接层、卷积层等）\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.自定义layer名1 = nn.layer层(参数)\n",
    "        self.自定义layer名2 = nn.layer层(参数)\n",
    "        self.自定义layer名3 = nn.Sequential(\n",
    "            nn.layer层(参数)，\n",
    "            nn.layer层(参数)\n",
    "        ）\n",
    "        \n",
    "    # 实现模型的功能，实现各个层之间的连接关系\n",
    "    # nn.functional实现不具有可学习参数的层(如ReLU、dropout、BatchNormanation层)的构造\n",
    "    def forward(self, x):\n",
    "        x = self.自定义layer名1(x)\n",
    "        x = F.不可学习参数层(x)\n",
    "        x = self.自定义layer名2(x)\n",
    "        x = 不可学习参数层(自定义layer名3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 实例化神经网络\n",
    "model实例 = 自定义神经网络类名()\n",
    "\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model实例, '存储路径')\n",
    "\n",
    "# 加载模型\n",
    "model = torch.load(\"model.pth\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-marble",
   "metadata": {},
   "source": [
    "#### ·可学习layer\n",
    "\n",
    ">**卷积层**\n",
    ">>nn.Conv2d(\n",
    ">>&nbsp;&nbsp;&nbsp;  in_channels = 输入特征矩阵的深度,   \n",
    ">>&nbsp;&nbsp;&nbsp;  out_channels = 卷积核数|输出特征矩阵深度,   \n",
    ">>&nbsp;&nbsp;&nbsp;  kernel_size = (卷积核长, 卷积核宽),   \n",
    ">>&nbsp;&nbsp;&nbsp;  stride = 卷积框步长,   \n",
    ">>&nbsp;&nbsp;&nbsp;  padding = (填充上下行数, 填充左右列数),   \n",
    ">>&nbsp;&nbsp;&nbsp;  dilation = 卷积核元素之间的间距1,   \n",
    ">>&nbsp;&nbsp;&nbsp;  groups = 从输入通道到输出通道的阻塞连接数1,   \n",
    ">>&nbsp;&nbsp;&nbsp;  bias = 添加偏置T/F,   \n",
    ">>&nbsp;&nbsp;&nbsp;  padding_mode = '填充数字zeros'  \n",
    ">>)\n",
    "\n",
    ">>说明：\n",
    ">>>in_channels = 输入通道维的元素数  \n",
    ">>>图像(通道，图像长，图像宽)（黑白图像通道=1，RGB图像通道=3）   \n",
    ">>>out_channels = 提取特征数 = 输出特征矩阵深度 = 输出特征矩阵通道维\n",
    "\n",
    ">**全连接层**\n",
    ">>nn.Linear(in_features=每个输入样本的大小, out_features=每个输出样本的大小)  \n",
    ">>说明：\n",
    "\n",
    "\n",
    "#### ·不可学习layer\n",
    ">**将多维数据转成一维**\n",
    ">>x.view(x.size(0), -1)  \n",
    ">>说明：在卷积层转全连接层之间使用，用在forward(self, x)中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "binding-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# 定义神经网络类\n",
    "class CNN(nn.Module):\n",
    "    # 可学习参数的层（如全连接层、卷积层等）\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 第一部分卷积层1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            # 卷积层(输入通道维1，输出通道维16，卷积窗口3*3)\n",
    "            nn.Conv2d(1, 16, kernel_size=(3,3), stride=1, padding=1),  # 维度变换(1,28,28) （黑白图像1通道，长28像素，宽28像素）->(16,28,28) （16个卷积核提取16个特征通道，长28，宽28）图像边缘扩展，没被卷积抛去\n",
    "            # 激活函数\n",
    "            nn.ReLU(),\n",
    "            # 池化层\n",
    "            nn.MaxPool2d(2) # 维度变化(16,28,28)->(16,14,14)\n",
    "        )\n",
    "            \n",
    "        #第二部分卷积层2\n",
    "        self.conv2 = nn.Sequential(\n",
    "            # 卷积层(输入通道维1，输出通道维16，卷积窗口3*3)\n",
    "            nn.Conv2d(16, 32, kernel_size=(3,3), stride=1, padding=1),  # 维度变换(16,14,14)->(32,14,14)\n",
    "            # 激活函数\n",
    "            nn.ReLU(),\n",
    "            # 池化层\n",
    "            nn.MaxPool2d(2) # 维度变化(32,14,14)->(32,7,7)\n",
    "        )\n",
    "            \n",
    "        # 全连接层\n",
    "        self.out = nn.Linear(32*7*7, 10)\n",
    "            \n",
    "            \n",
    "        \n",
    "    # 实现模型的功能，实现各个层之间的连接关系\n",
    "    # nn.functional实现不具有可学习参数的层(如ReLU、dropout、BatchNormanation层)的构造\n",
    "    def forward(self, x):\n",
    "        # 执行卷积层1 conv1\n",
    "        x = self.conv1(x)\n",
    "        # 执行卷积层2 conv2\n",
    "        x = self.conv2(x)\n",
    "        # 将图像数据转为1维\n",
    "        x = x.view(x.size(0),-1)\n",
    "        # 执行全连接层 out\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfa53c7",
   "metadata": {},
   "source": [
    "# 4.训练模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2039f4b1",
   "metadata": {},
   "source": [
    "#### 方法一 ：利用torchkeras包训练\n",
    "\n",
    "(需要torchkeras支持)  \n",
    "import from torchkeras import summary,Model \n",
    "\n",
    "1.实例化模型  \n",
    "```\n",
    "model = Model(自定义神经网络类名())\n",
    "```\n",
    "\n",
    "2.编译模型\n",
    "```\n",
    "model.compile(loss_func = 损失函数,\n",
    "             optimizer= 优化方法,\n",
    "             metrics_dict={\"accuracy\":accuracy})\n",
    "```\n",
    "\n",
    "3.训练模型\n",
    "```\n",
    "dfhistory = model.fit(训练次数,train_loader, test_loader, log_step_freq=100) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b593b836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (net): CNN(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 28, 28]             160\n",
      "              ReLU-2           [-1, 16, 28, 28]               0\n",
      "         MaxPool2d-3           [-1, 16, 14, 14]               0\n",
      "            Conv2d-4           [-1, 32, 14, 14]           4,640\n",
      "              ReLU-5           [-1, 32, 14, 14]               0\n",
      "         MaxPool2d-6             [-1, 32, 7, 7]               0\n",
      "            Linear-7                   [-1, 10]          15,690\n",
      "================================================================\n",
      "Total params: 20,490\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.002991\n",
      "Forward/backward pass size (MB): 0.323074\n",
      "Params size (MB): 0.078163\n",
      "Estimated Total Size (MB): 0.404228\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from torchkeras import summary,Model\n",
    "\n",
    "# 实例化模型\n",
    "model = Model(CNN())\n",
    "model = model.float()\n",
    "\n",
    "# 查看模型\n",
    "print(model)\n",
    "print(summary(model, input_shape=(1,28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69746c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def accuracy(y_pred,y_true):\n",
    "    y_pred_cls = torch.argmax(nn.Softmax(dim=1)(y_pred),dim=1).data\n",
    "    return accuracy_score(y_true.numpy(),y_pred_cls.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71543cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss_func = nn.CrossEntropyLoss(),\n",
    "             optimizer= torch.optim.Adam(model.parameters(),lr = 0.02),\n",
    "             metrics_dict={\"accuracy\":accuracy})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57bbfa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training ...\n",
      "\n",
      "================================================================================2021-11-29 15:26:56\n",
      "{'step': 100, 'loss': 0.679, 'accuracy': 0.793}\n",
      "{'step': 200, 'loss': 0.461, 'accuracy': 0.859}\n",
      "{'step': 300, 'loss': 0.383, 'accuracy': 0.883}\n",
      "{'step': 400, 'loss': 0.334, 'accuracy': 0.898}\n",
      "{'step': 500, 'loss': 0.302, 'accuracy': 0.908}\n",
      "{'step': 600, 'loss': 0.277, 'accuracy': 0.916}\n",
      "{'step': 700, 'loss': 0.26, 'accuracy': 0.92}\n",
      "{'step': 800, 'loss': 0.245, 'accuracy': 0.925}\n",
      "{'step': 900, 'loss': 0.237, 'accuracy': 0.927}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   1   | 0.235 |  0.928   |  0.114   |    0.965     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2021-11-29 15:27:11\n",
      "{'step': 100, 'loss': 0.145, 'accuracy': 0.953}\n",
      "{'step': 200, 'loss': 0.147, 'accuracy': 0.955}\n",
      "{'step': 300, 'loss': 0.143, 'accuracy': 0.955}\n",
      "{'step': 400, 'loss': 0.146, 'accuracy': 0.954}\n",
      "{'step': 500, 'loss': 0.143, 'accuracy': 0.956}\n",
      "{'step': 600, 'loss': 0.141, 'accuracy': 0.957}\n",
      "{'step': 700, 'loss': 0.141, 'accuracy': 0.956}\n",
      "{'step': 800, 'loss': 0.142, 'accuracy': 0.956}\n",
      "{'step': 900, 'loss': 0.141, 'accuracy': 0.957}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   2   | 0.141 |  0.957   |  0.113   |    0.966     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2021-11-29 15:27:26\n",
      "{'step': 100, 'loss': 0.126, 'accuracy': 0.961}\n",
      "{'step': 200, 'loss': 0.127, 'accuracy': 0.96}\n",
      "{'step': 300, 'loss': 0.126, 'accuracy': 0.96}\n",
      "{'step': 400, 'loss': 0.128, 'accuracy': 0.96}\n",
      "{'step': 500, 'loss': 0.126, 'accuracy': 0.961}\n",
      "{'step': 600, 'loss': 0.125, 'accuracy': 0.961}\n",
      "{'step': 700, 'loss': 0.128, 'accuracy': 0.961}\n",
      "{'step': 800, 'loss': 0.129, 'accuracy': 0.961}\n",
      "{'step': 900, 'loss': 0.129, 'accuracy': 0.961}\n",
      "\n",
      " +-------+------+----------+----------+--------------+\n",
      "| epoch | loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+------+----------+----------+--------------+\n",
      "|   3   | 0.13 |  0.961   |  0.109   |    0.967     |\n",
      "+-------+------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2021-11-29 15:27:41\n",
      "Finished Training...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dfhistory = model.fit(3,train_loader, test_loader, log_step_freq=100) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e561eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型 .save('模型.h5')\n",
    "\n",
    "torch.save(model,'pytorch_number_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e460e1ba",
   "metadata": {},
   "source": [
    "#### 方法二：手动训练\n",
    "\n",
    "1.实例化模型\n",
    "```\n",
    "model变量 = 自定义神经网络类名()\n",
    "```\n",
    "\n",
    "2.定义损失函数和优化器\n",
    "```\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model变量.parameters(), lr = 学习率) \n",
    "```\n",
    "\n",
    "3.训练模型\n",
    "```\n",
    "for epoch in range(训练轮数):  # 训练轮数\n",
    "    \n",
    "    # 遍历训练集每条数据，进行训练 \n",
    "    running_loss = 0.0 # 记录一轮中每条训练数据预测的损失累加\n",
    "    for step, (x, y) in enumerate(训练集加载train_loader):   #【enumerate()枚举对象 得到格式（id，元素）】\n",
    "        b_x = Variable(x) # 数据x\n",
    "        b_y = Variable(y) # 标签y\n",
    "    \n",
    "        output = model_2(b_x) # 把数据输入进网络\n",
    "        loss = loss_func(output, b_y) # 计算一条数据的损失\n",
    "        running_loss += loss.item() # 损失累加\n",
    "        \n",
    "        optimizer.zero_grad() # 梯度置零\n",
    "        loss.backward()  # loss反向传播\n",
    "        optimizer.step() # 反向传播后参数更新\n",
    "        \n",
    "    \n",
    "    print('训练轮数：', epoch, ' 平均损失：',running_loss/len(train_loader)) #平均损失=每轮每条训练数据损失求和/每轮训练数据数\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c03e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "model_2 = CNN()\n",
    "\n",
    "# 查看模型\n",
    "print(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d52593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(model_2.parameters(), lr = 0.02) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a3c953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练轮数： 0  训练平均损失loss： 0.3537669796198765\n",
      "训练轮数： 0  测试平均损失val_loss： 0.15308491075744055\n",
      "训练轮数： 1  训练平均损失loss： 0.15160430645617817\n",
      "训练轮数： 1  测试平均损失val_loss： 0.11994938095310881\n",
      "训练轮数： 2  训练平均损失loss： 0.13806999639780726\n",
      "训练轮数： 2  测试平均损失val_loss： 0.11582504276053182\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "EPOCH = 3 # 训练轮数\n",
    "\n",
    "#记录用于绘图\n",
    "losses = []#记录每次迭代后训练的loss\n",
    "eval_losses = []#测试的\n",
    "\n",
    "\n",
    "\n",
    "# 自定义训练方法\n",
    "\n",
    "for epoch in range(EPOCH):  # 训练轮数\n",
    "    # 遍历训练集每条数据，进行训练，得到每轮损失loss\n",
    "    running_loss = 0.0\n",
    "    for step, (x, y) in enumerate(train_loader):   #【enumerate()枚举对象 得到格式（id，元素）】\n",
    "        b_x = Variable(x) # 数据x\n",
    "        b_y = Variable(y) # 标签y\n",
    "    \n",
    "        output = model_2(b_x) # 把数据输入进网络\n",
    "        loss = loss_func(output, b_y) # 计算一条数据的损失\n",
    "        running_loss += loss.item() # 损失累加\n",
    "        \n",
    "        optimizer.zero_grad() # 梯度置零\n",
    "        loss.backward()  # loss反向传播\n",
    "        optimizer.step() # 反向传播后参数更新\n",
    "    \n",
    "    losses.append(running_loss/len(train_loader)) # 记录该轮平均损失，后续用于画图\n",
    "    print('训练轮数：', epoch, ' 训练平均损失loss：',running_loss/len(train_loader)) #平均损失=每轮每条训练数据损失求和/每轮训练数据数\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 遍历测试集每条数据，进行测试，每轮训练后损失val_loss\n",
    "    running_loss = 0.0\n",
    "    for step, (x, y) in enumerate(test_loader): \n",
    "        b_x = Variable(x) # 数据x\n",
    "        b_y = Variable(y) # 标签y\n",
    "        \n",
    "        output = model_2(b_x) # 把数据输入进网络\n",
    "        loss = loss_func(output, b_y) # 计算一条数据的损失\n",
    "        running_loss += loss.item() # 损失累加\n",
    "    \n",
    "    eval_losses.append(running_loss/len(test_loader)) # 记录该轮平均损失，后续用于画图\n",
    "    print('训练轮数：', epoch, ' 测试平均损失val_loss：',running_loss/len(test_loader)) #平均损失=每轮每条训练数据损失求和/每轮训练数据数\n",
    "    \n",
    "        \n",
    "    \n",
    "print('end') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dc3433e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 画图\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(losses)), losses, marker='o',label='losses')\n",
    "plt.plot(range(len(eval_losses)), eval_losses, marker='*',label='eval_losses')\n",
    "plt.legend() #图例\n",
    "plt.title(\"loss\") #标题\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55d33dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型 .save('模型.h5')\n",
    "\n",
    "torch.save(model_2,'pytorch_number_model_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1ff6c5",
   "metadata": {},
   "source": [
    "# 5.模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b358f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchkeras import summary,Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# 加载模型\n",
    "\n",
    "#方法一训练模型\n",
    "model = torch.load('pytorch_number_model.h5')\n",
    "#方法二训练模型\n",
    "model_2 = torch.load('pytorch_number_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手动导入预测数据\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() \n",
    "\n",
    "# 取前4张图片\n",
    "test_images = test_images[2:6]\n",
    "test_labels = test_labels[2:6]\n",
    "print('图片原始格式:', test_images.shape)\n",
    "print('标签：', test_labels)\n",
    "\n",
    "# 图片格式转换成tensor格式\n",
    "test_images = torch.tensor(test_images)\n",
    "print('图片转换成tensor格式后：', test_images.shape)\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(test_images[i])\n",
    "plt.show\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0208ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "# 图片类型转换成FloatTensor(预测和训练数据类型一致)\n",
    "test_images = test_images.type(torch.FloatTensor)/255\n",
    "\n",
    "print(test_images.shape)\n",
    "print(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72140cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为图片格式添加通道维\n",
    "pic = test_images[0:4]\n",
    "\n",
    "pic = pic.reshape(4,1,28,28)\n",
    "print('添加通道维度', pic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6ee79",
   "metadata": {},
   "source": [
    "#### 方法一模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测模式\n",
    "\n",
    "output = model(pic)\n",
    "print(output)\n",
    "\n",
    "print('------')\n",
    "# 按行找到一行内值最大的列号\n",
    "prediction = torch.max(output, dim=1)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50953cf",
   "metadata": {},
   "source": [
    "#### 方法二模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918258ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_2(pic)\n",
    "print(output)\n",
    "\n",
    "print('------')\n",
    "# 按行找到一行内值最大的列号\n",
    "prediction = torch.max(output, dim=1)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42f8420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
